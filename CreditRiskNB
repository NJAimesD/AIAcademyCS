{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1207035,"sourceType":"datasetVersion","datasetId":688532}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Risk Analysis\n## AI Pioneers\n\n### Here, we´ll analyze a dataset containing several variables, and it´s outcome is the person credit status (default/ non default), we´ll compare different ML aproaches and select the best fit to solve the problem.","metadata":{}},{"cell_type":"markdown","source":"### Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nplt. style. use ('ggplot')\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/credit-risk-dataset/credit_risk_dataset.csv')\nprint(f\"We have {df.shape[1]-1} variables and {df.shape[0]} registers in the dataset.\\n\")\ndf.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\nhousing = df['person_home_ownership'].unique()\nsns.countplot(x='person_home_ownership',order = housing, data = df,hue='loan_status', palette = sns.color_palette(palette=\"cubehelix\")[:2][::-1])\nplt.legend(labels=[\"Non-Default\", \"Default\"])\nplt.xlabel(\"Home Ownership Status\")\nplt.ylabel(\"Individuals count\")\nplt.title(\"Comparison Housing Status and Loan Status\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\ngrades = sorted(df['loan_grade'].unique())\nsns.countplot(x='loan_grade',order = grades, data = df,hue='loan_status', palette = sns.color_palette(palette=\"cubehelix\")[:2][::-1])\nplt.xlabel(\"Loan Grade\")\nplt.ylabel(\"Individuals count\")\nplt.legend(labels=[\"Non-Default\", \"Default\"])\nplt.title(\"Comparison Loan Grade and Loan Status\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nintent = df['loan_intent'].unique()\nsns.countplot(x='loan_intent',order = intent, data = df,hue='loan_status', palette = sns.color_palette(palette=\"cubehelix\")[:2][::-1])\nplt.legend(labels=[\"Non-Default\", \"Default\"])\nplt.xlabel(\"Loan Intent\")\nplt.ylabel(\"Individuals count\")\nplt.title(\"Comparison Loan Intent and Loan Status\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=[\"person_home_ownership\", \"loan_intent\", \"loan_grade\", \"cb_person_default_on_file\"]) \ndf.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define our X and Y data, loan_status is our target variable.\nY = df[\"loan_status\"]\nX = df.drop(columns=[\"loan_status\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ones = sum(Y)\nzeros = len(Y)-ones\nplt.bar([\"Default\",\"Non Default\"],[ones, zeros], color= [\"teal\", \"goldenrod\"]);\nplt.title(\"Balance of data\");\nplt.xlabel(\"Loan Status\");\nplt.ylabel(\"Data available\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import BorderlineSMOTE\n\nsmote = BorderlineSMOTE()\nX, Y = smote.fit_resample(X, Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \n\nX_train, X_test, y_train, y_test = train_test_split(X,Y ,random_state=10, test_size=0.2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if the data is balanced or not\nones = sum(Y)\nzeros = len(Y)-ones\nplt.bar([\"Default\",\"Non Default\"],[ones, zeros], color= [\"teal\", \"goldenrod\"]);\nplt.title(\"Balance of data\");\nplt.xlabel(\"Loan Status\");\nplt.ylabel(\"Data available\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(X.person_age, bins = 50);\nplt.title(\"Distribution of age\");","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.select_dtypes(include='number').corr(),annot=True,cmap=\"RdYlGn\");\nplt.title(\"Correlation matrix\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_corrs(corrs):\n    return pd.concat([corrs[0:3],corrs[-3:]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrs = get_corrs(df.corr()['loan_status'].sort_values().drop('loan_status'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(9, 7))\ncorrs.plot(kind='bar', color=(corrs > 0).map({True: sns.color_palette(palette=\"cubehelix\")[1], False: sns.color_palette(palette=\"cubehelix\")[0]}))\nplt.title(\"Correlations to Loan Status\");\nplt.ylabel(\"Correlation coefficient\")\n#ax.bar_label([\"Loan Grade A\", \"Home Mortgage\", \"No Historical default\", \"Loan Grade D\", \"Interest Rate\", \"Loan as percent of income\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.apply(pd.to_numeric)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, Markdown, Latex","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [LinearRegression(),LogisticRegression(C=1e5), Ridge(alpha = 0.5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_binary(Y):\n    y_binary = []\n    for value in Y:\n        y_binary.append(1) if value>0.5 else y_binary.append(0)\n    return y_binary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_mat(y,y_pred, model_name):\n    ax= plt.subplot()\n    sns.heatmap(confusion_matrix(y, y_pred),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\n    plt.title(f\"Confusion matrix for {model_name}\")\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n    return plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc(y,y_pred, model_name):\n    fig, ax = plt.subplots(figsize=(11, 7))\n    fpr, tpr, thresh = roc_curve(y, y_pred)\n    aucknn = roc_auc_score(y, y_pred)\n    ax.plot(fpr, tpr, label=f'AUC = {str(round(aucknn,3))}', color = \"darkgreen\", linestyle = \"dashed\")\n    print(fpr, tpr)\n    ax.plot([0,1],[0,1], label=\"Naive model\", color = \"black\");\n    plt.legend()\n    plt.title(f\"ROC Curve for {model_name}\")\n    ax.fill_between(fpr, tpr, color='darkgreen', alpha=0.3)\n    return plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_importance(model, features, num=len(X)):\n    feature_imp = pd.DataFrame({\"Value\": model.feature_importances_, \"Feature\": features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n    plt.title(f\"Features weight for { type(model).__name__}\")\n    plt.tight_layout()\n    return plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = {}\nfor model in linear_models:\n    display(Markdown(f'### {type(model).__name__}:\\n'))\n    model.fit(X_train, y_train)\n    ytest_pred = model.predict(X_test)\n    \n    confusion_mat(y_test,get_binary(ytest_pred), type(model).__name__)\n    #Metrics\n    report = classification_report(y_test,get_binary(ytest_pred), output_dict=True)\n    display(Markdown(f\"#### Classification Report for {type(model).__name__}\\n\"))\n    display(Markdown(classification_report(y_test,get_binary(ytest_pred))))\n    metrics[type(model).__name__] = report['macro avg']\n    \n    #ROC\n    plot_roc(y_test, ytest_pred, type(model).__name__ )\n    display(Markdown('## -------------------------------------------------------------------------------------'))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = LogisticRegression(C=1e5, class_weight='balanced')\nmodel1.fit(X, Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model1.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nsns.heatmap(confusion_matrix(Y, y_pred),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(Y,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_binary(Y):\n    y_binary = []\n    for value in Y:\n        y_binary.append(1) if value>0.5 else y_binary.append(0)\n    return y_binary\nmodel2 = LinearRegression()\nmodel2.fit(X, Y)\ny_pred = model2.predict(X) \nfrom sklearn.metrics import confusion_matrix, classification_report\nsns.heatmap(confusion_matrix(Y, get_binary(y_pred)),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(Y,get_binary(y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nmodel3 = Ridge(alpha = 0.5)\nmodel3.fit(X, Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model3.predict(X) \n\nsns.heatmap(confusion_matrix(Y, get_binary(y_pred)),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(Y,get_binary(y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Next step: Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nmodel4 = RandomForestClassifier(n_estimators=15, random_state=10)\nmodels = [(RandomForestClassifier(n_estimators=15, random_state=10)),XGBClassifier(n_estimators = 12, random_state = 10, gamma = 0.05) ]\nfor model in models:\n    display(Markdown(f'### {type(model).__name__}:\\n'))\n    model.fit(X_train, y_train)\n    ytest_pred = model.predict(X_test)\n    \n    confusion_mat(y_test,get_binary(ytest_pred), type(model).__name__)\n    #Metrics\n    report = classification_report(y_test,get_binary(ytest_pred), output_dict=True)\n    display(Markdown(f\"#### Classification Report for {type(model).__name__}\\n\"))\n    print(classification_report(y_test,get_binary(ytest_pred)))\n    metrics[type(model).__name__] = report['macro avg']\n    \n    #ROC\n    plot_roc(y_test, ytest_pred, type(model).__name__ )\n    \n    plot_importance(model, X_train)\n    display(Markdown('## -------------------------------------------------------------'))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\njoblib.dump(model4, \"credit_random_forest.joblib\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train set","metadata":{}},{"cell_type":"code","source":"model4 = RandomForestClassifier(n_estimators=15, random_state=10)\nmodel4.fit(X_train, y_train)\nytrain_pred = model4.predict(X_train) \nsns.heatmap(confusion_matrix(y_train, ytrain_pred),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(y_train,ytrain_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test set","metadata":{}},{"cell_type":"code","source":"ytest_pred = model4.predict(X_test) \nsns.heatmap(confusion_matrix(y_test, ytest_pred),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(y_test,ytest_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve\nfpr, tpr, thresh = roc_curve(y_test, ytest_pred)\naucknn = roc_auc_score(y_test, ytest_pred)\nplt.plot(fpr, tpr, label=f'AUC = {str(round(aucknn,3))}')\nplt.plot([0,1],[0,1], label=\"Naive model\");\nplt.legend()\nplt.title(\"ROC Curve for Random Forest\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_importance(model, features, num=len(X)):\n    feature_imp = pd.DataFrame({\"Value\": model.feature_importances_, \"Feature\": features.columns})\n    plt.figure(figsize=(17, 8))\n    sns.barplot(y=\"Value\", x=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:8])\n    plt.title(f\"Features weight for { type(model).__name__}\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(model4, X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xboost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel5 = XGBClassifier(n_estimators = 12, random_state = 10, gamma = 0.05)\nmodel5.fit(X_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytest_pred = model5.predict(X_test) \nsns.heatmap(confusion_matrix(y_test, ytest_pred),cmap=\"RdYlGn\", annot = True, fmt=\"d\")\nplt.title(\"Confusion matrix\")\nprint(\"Classification Report\\n\",classification_report(y_test,ytest_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_auc(model, y_test, y_test_pred, name):\n    fpr, tpr, thresh = roc_curve(y_test, ytest_pred)\n    aucknn = roc_auc_score(y_test, ytest_pred)\n    plt.plot(fpr, tpr, label=f'AUC = {str(round(aucknn,3))}')\n    plt.plot([0,1],[0,1], label=\"naive model\");\n    plt.legend()\n    plt.title(f\"ROC Curve for {name}\")\n    plt.show()\nplot_auc(model5,y_test, ytest_pred, \"Xboost\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(model5, X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparative\n","metadata":{}},{"cell_type":"code","source":"model.__name__ = \"Neural_Network\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [model1,model2, model3,model4,model5]\nfor model in models:\n    model.fit(X_train,y_train)\n    ytest_pred = model.predict(X_test)\n    fpr, tpr, thresh = roc_curve(y_test, ytest_pred)\n    aucknn = roc_auc_score(y_test, ytest_pred)\n    plt.plot(fpr, tpr, label=f'{type(model).__name__} = {str(round(aucknn,3))}')\n    plt.title(f\"ROC Curve Comparison\")\nplt.plot([0,1],[0,1], label=\"Naive Model\")\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Network","metadata":{}},{"cell_type":"code","source":"X_train = np.asarray(X_train).astype(np.float32)\ny_train = np.asarray(y_train).astype(np.float32)\nX_test = np.asarray(X_test).astype(np.float32)\ny_test = np.asarray(y_test).astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nimport keras\nmodel = Sequential()\nmodel.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.1), metrics=['accuracy'])\nhistory = model.fit(scaler.transform(X_train), y_train, epochs=100, batch_size = 456, validation_data=(scaler.transform(X_test), y_test))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title(\"Accuracy Evolution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytest_pred = model.predict(X_test)\nfpr, tpr, thresh = roc_curve(y_test, ytest_pred)\naucknn = roc_auc_score(y_test, ytest_pred)\nplt.plot(fpr, tpr, label=f'{type(model).__name__} = {str(round(aucknn,3))}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytest_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[\"Neural_Network\"]= ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}